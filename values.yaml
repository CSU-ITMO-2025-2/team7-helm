replicaCount: 2

image:
  repository: buldakovn/flask-app
  tag: "latest"
  pullPolicy: Always

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

serviceAccount:
  create: true
  annotations: {}
  name: ""

podAnnotations: {}

podSecurityContext: {}

securityContext: {}

service:
  type: ClusterIP
  port: 5000

# Startup Probe - проверяет, что приложение запустилось
# Используется для приложений с медленным стартом
startupProbe:
  enabled: true
  path: /health/startup
  initialDelaySeconds: 0
  periodSeconds: 10
  timeoutSeconds: 3
  failureThreshold: 30  # Максимум 5 минут на запуск (30 * 10 секунд)

# Liveness Probe - проверяет, что приложение все еще работает
# Если проверка не проходит, Kubernetes перезапускает контейнер
livenessProbe:
  enabled: true
  path: /health/live
  initialDelaySeconds: 30
  periodSeconds: 10
  timeoutSeconds: 5
  failureThreshold: 3

# Readiness Probe - проверяет, готово ли приложение принимать трафик
# Если проверка не проходит, под удаляется из Service endpoints
readinessProbe:
  enabled: true
  path: /health/ready
  initialDelaySeconds: 10
  periodSeconds: 5
  timeoutSeconds: 3
  failureThreshold: 3


ingress:
  enabled: true
  host: team7.kubepractice.ru
  className: nginx
  annotations: {}
  tls:
    enabled: false
    secretName: tls-secret

resources:
  limits:
    cpu: 500m
    memory: 512Mi
  requests:
    cpu: 100m
    memory: 128Mi

autoscaling:
  enabled: false
  minReplicas: 1
  maxReplicas: 5
  targetCPUUtilizationPercentage: 80

nodeSelector: {}

tolerations: []

affinity: {}

# External Secret configuration для интеграции с Vault
# Требуется установленный External Secrets Operator в кластере
# И настроенный SecretStore/ClusterSecretStore для подключения к Vault
externalSecret:
  enabled: true
  refreshInterval: 1h  # Как часто обновлять секрет из Vault
  secretStore:
    name: vault-team7  # Имя SecretStore или ClusterSecretStore (должен быть создан отдельно)
    kind: SecretStore  # SecretStore (namespace-scoped) или ClusterSecretStore (cluster-scoped)
  # Секреты из test (kv/data/team7/test)
  test:
    enabled: true
    data:
      - secretKey: HELLO_MESSAGE  # Имя ключа в Kubernetes Secret (будет переменной окружения)
        remoteRef:
          key: kv/data/team7/test  # Путь к секрету в Vault
          property: TEST_MESSAGE  # Конкретное свойство из секрета
  
  # Секреты PostgreSQL из pgsql (kv/data/team7/pgsql)
  pgsql:
    enabled: true
    data:
      - secretKey: PG_HOST
        remoteRef:
          key: kv/data/team7/pgsql
          property: PG_HOST
      - secretKey: PG_PORT
        remoteRef:
          key: kv/data/team7/pgsql
          property: PG_PORT
      - secretKey: PG_DATABASE
        remoteRef:
          key: kv/data/team7/pgsql
          property: PG_DATABASE
      - secretKey: PG_USER
        remoteRef:
          key: kv/data/team7/pgsql
          property: PG_USER
      - secretKey: PG_PASSWORD
        remoteRef:
          key: kv/data/team7/pgsql
          property: PG_PASSWORD
  
  # Секреты Kafka из Vault (kv/data/team7/kafka)
  kafka:
    enabled: true
    data:
      - secretKey: KAFKA_USERNAME  # Имя пользователя Kafka
        remoteRef:
          key: kv/data/team7/kafka  # Путь к секрету Kafka в Vault
          property: KAFKA_USERNAME  # Свойство из секрета в Vault
      - secretKey: KAFKA_PASSWORD  # Пароль пользователя Kafka (должно совпадать с kafka.users.producer.secretKey)
        remoteRef:
          key: kv/data/team7/kafka  # Путь к секрету Kafka в Vault
          property: KAFKA_PASSWORD  # Свойство из секрета в Vault
  
  # Секреты S3 из Vault (kv/data/team7/s3)
  s3:
    enabled: true
    data:
      - secretKey: AWS_ACCESS_KEY_ID  # Access Key ID для S3
        remoteRef:
          key: kv/data/team7/s3  # Путь к секрету S3 в Vault
          property: AWS_ACCESS_KEY_ID  # Свойство из секрета в Vault
      - secretKey: AWS_SECRET_ACCESS_KEY  # Secret Access Key для S3
        remoteRef:
          key: kv/data/team7/s3  # Путь к секрету S3 в Vault
          property: AWS_SECRET_ACCESS_KEY  # Свойство из секрета в Vault
      - secretKey: AWS_ENDPOINT_URL  # Endpoint URL для S3-совместимых хранилищ (опционально)
        remoteRef:
          key: kv/data/team7/s3  # Путь к секрету S3 в Vault
          property: AWS_ENDPOINT_URL  # Свойство из секрета в Vault

# Kafka configuration через Strimzi Operator
# Используется Apache Kafka в режиме KRaft (без Zookeeper)
kafka:
  enabled: true
  clusterName: "kafka-cluster"  # Имя кластера Kafka (используется в strimzi.io/cluster label)
  image:
    # В Strimzi образ управляется оператором, версия указывается отдельно
    tag: "4.1.1"  # Версия Kafka (поддерживаемые: 4.0.0, 4.0.1, 4.1.0, 4.1.1)
  # Настройки реплик для NodePools
  broker:
    replicas: 3  # Количество брокеров (минимум 3 для production)
  controller:
    replicas: 3  # Количество контроллеров (3 для кворума)
  # Cruise Control для автоматической ребалансировки при масштабировании
  cruiseControl:
    enabled: true  # Включить Cruise Control (активируется при broker.replicas >= 2)
    resources:
      requests:
        cpu: 200m
        memory: 512Mi
      limits:
        cpu: 500m
        memory: 1Gi
    # Автоматическая ребалансировка при добавлении/удалении брокеров
    autoRebalance:
      - mode: add-brokers  # Ребалансировка при добавлении брокеров
      - mode: remove-brokers  # Ребалансировка при удалении брокеров
  # Настройки репликации для отказоустойчивости
  minInSyncReplicas: 2  # Минимум 2 синхронизированные реплики для подтверждения записи
  offsetsTopicReplicationFactor: 3  # Репликация системного топика offsets
  transactionStateLogReplicationFactor: 3  # Репликация транзакционного лога
  transactionStateLogMinIsr: 2  # Минимум ISR для транзакций
  defaultReplicationFactor: 3  # Репликация по умолчанию для новых топиков
  # Хранилище для Kafka
  storage:
    type: "ephemeral"  # ephemeral или persistent-claim (для production используйте persistent-claim)
    size: "10Gi"  # Используется только для persistent-claim
    class: ""  # Storage class (опционально)
  # Ресурсы для Kafka брокеров
  resources:
    requests:
      cpu: 500m
      memory: 1Gi
    limits:
      cpu: 750m  # Уменьшено для соответствия ResourceQuota (нужно место для entity-operator)
      memory: 2Gi
  # Дополнительные настройки Kafka
  logRetentionMs: 86400000  # Время хранения логов (1 день)
  logSegmentBytes: 1073741824  # Размер сегмента лога (1Gi)
  # Топики для создания
  topics:
    name: "events"
    partitions: 6  # Больше партиций для лучшего распределения нагрузки
    replicas: 3  # Репликация на все 3 брокера
    retentionMs: 86400000  # 1 день
    segmentBytes: 1073741824  # 1Gi
  users:
    # Имя пользователя Kafka (должно соответствовать значению KAFKA_USERNAME из секрета)
    # Это значение должно совпадать с тем, что хранится в Vault в kv/data/team7/kafka -> KAFKA_USERNAME
    username: producer  # Замените на реальное имя пользователя из секрета
    secretKey: "KAFKA_PASSWORD"  # Не используется напрямую, пароль берется из секрета
# Конфигурация приложения для работы с Kafka
app:
  kafka:
    enabled: true
    # Имя сервиса Kafka формируется как <release-name>-kafka:9092
    # Оставьте пустым для автоматического определения
    bootstrapServers: "kafka-cluster-kafka-bootstrap"  # Оставьте пустым для автоматического определения, или укажите явно
    topic: "events"  # Топик по умолчанию
    consumerGroup: "flask-app-consumer"  # Consumer group ID

# Kafka UI для визуального управления Kafka кластером
# Использует provectus/kafka-ui
kafkaUi:
  enabled: true
  image:
    repository: ghcr.io/kafbat/kafka-ui
    tag: "latest"
    pullPolicy: IfNotPresent
  # Ресурсы для Kafka UI (Java приложение требует больше памяти)
  resources:
    requests:
      cpu: 100m
      memory: 512Mi
    limits:
      cpu: 500m
      memory: 768Mi
  # Настройки сервиса
  service:
    type: ClusterIP
    port: 8080
  # Настройки подключения к Kafka
  kafka:
    # Bootstrap server для Strimzi Kafka
    # По умолчанию: kafka-cluster-kafka-bootstrap:9092
    bootstrapServers: "kafka-cluster-kafka-bootstrap:9092"
    # Название кластера в UI
    clusterName: "team7-kafka"
    # SCRAM-SHA-512 аутентификация (credentials берутся из externalSecret.kafka)
    auth:
      enabled: true
      mechanism: "SCRAM-SHA-512"
      protocol: "SASL_PLAINTEXT"

